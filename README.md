# Buddy AI Assistant ğŸ¤–

An emotionally intelligent AI assistant with voice capabilities, powered by Microsoft Phi-2 language model and advanced sentiment analysis.

![Status](https://img.shields.io/badge/status-production%20ready-brightgreen)
![Python](https://img.shields.io/badge/python-3.12%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.5.0-red)

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Usage Modes](#-usage-modes)
- [Project Structure](#-project-structure)
- [Configuration](#-configuration)
- [API Reference](#-api-reference)
- [Testing](#-testing)
- [Troubleshooting](#-troubleshooting)
- [Performance](#-performance)

---

## ğŸŒŸ Overview

Buddy is a conversational AI assistant designed for Windows environments with:

- **Natural Language Understanding** via Microsoft Phi-2 (2.7B parameters)
- **Voice Interaction** with speech recognition and text-to-speech
- **Emotion Analysis** using dual sentiment/emotion detection models
- **Context Awareness** with conversation history tracking
- **Safety Filtering** for inappropriate content
- **Multiple Deployment Options** (CLI, Voice, API Server)

### Key Technologies
- **Language Model**: Microsoft Phi-2 / TinyLlama  
- **Sentiment Analysis**: DistilBERT (SST-2)
- **Emotion Detection**: Twitter-RoBERTa
- **Speech Recognition**: Google Speech API
- **TTS Engine**: pyttsx3
- **Web Framework**: FastAPI

---

## âœ¨ Features

### Core Capabilities
âœ… Interactive natural conversations  
âœ… Voice input and output support  
âœ… Real-time sentiment analysis  
âœ… Multi-modal input (text & voice)  
âœ… Content safety filtering  
âœ… Visual typing indicators  

### Safety & Quality
ğŸ›¡ï¸ Automatic content moderation  
ğŸ›¡ï¸ Anti-repetition validation  
ğŸ›¡ï¸ Graceful error handling  
ğŸ›¡ï¸ CPU-optimized inference  

### Deployment Options
1. **CLI Mode** - Text-based terminal interface
2. **Voice Mode** - Voice-activated assistant
3. **API Server** - RESTful API with FastAPI
4. **Lightweight Mode** - Minimal resource variant

---

## ğŸ’¾ Installation

### Prerequisites
- Python 3.12+
- 4GB RAM minimum (8GB recommended)
- 10GB free disk space
- Windows 10/11
- Internet connection (first run)

### Steps

1. **Clone/Download Project**
   ```bash
   cd D:\Madhur\ai_assistant_project
   ```

2. **Install Dependencies**
   ```bash
   pip install --user -r requirements.txt
   ```

3. **Fix PyTorch (Windows)**
   ```bash
   python fix_torch.py
   ```

4. **Verify Installation**
   ```bash
   python test_syntax.py
   ```

Expected output: `ğŸ‰ All files have valid syntax!`

---

## ğŸš€ Quick Start

### 3-Step Launch

1. **Run the application**
   ```bash
   python app.py
   ```

2. **Select input mode**
   - Press `2` for Text Input (recommended)
   - Press `1` for Voice Input

3. **Start chatting**
   ```
   You: Hello Buddy!
   Buddy: Hello! How can I help you today?
   (Responded in 2.45s)
   
   You: quit
   ğŸ‘‹ Session ended
   ```

### Example Session
```
ğŸŒŸ Buddy AI Assistant ğŸŒŸ
Choose input method:
1. Voice
2. Text
Selection (1/2): 2

You: What is Python?
Buddy: Python is a high-level programming language known for its simplicity 
and readability, widely used in web development and data science.
(Responded in 3.12s)

You: exit
ğŸ‘‹ Session ended
```

---

## ğŸ® Usage Modes

### 1. CLI Mode (Text)
```bash
python app.py
# Select option 2
```

Features: Text I/O, response timing, TTS playback

### 2. Voice Mode
```bash
python app.py
# Select option 1
```

Features: Microphone input, speech recognition, audio feedback

Requirements: Microphone, internet connection

### 3. API Server
```bash
python start_buddy.py
# Or: python phi_inference.py api
```

Starts REST API on `http://localhost:8000`

**Endpoint**: `POST /chat`

Request:
```json
{
  "text": "Hello!",
  "use_cache": true
}
```

Response:
```json
{
  "response": "Hello! How can I help?",
  "status": "success"
}
```

---

## ğŸ“ Project Structure

```
buddy-ai-assistant/
â”‚
â”œâ”€â”€ ğŸ“„ Core Application
â”‚   â”œâ”€â”€ app.py                  # Main CLI application
â”‚   â”œâ”€â”€ core.py                 # BuddyCore with Phi-2
â”‚   â”œâ”€â”€ speech.py               # Voice I/O handling
â”‚   â”œâ”€â”€ utils.py                # Utility functions
â”‚   â””â”€â”€ config.py               # Configuration
â”‚
â”œâ”€â”€ ğŸ¤– AI Models & APIs
â”‚   â”œâ”€â”€ phi_inference.py        # Full API server
â”‚   â”œâ”€â”€ buddy_api.py            # Optimized API
â”‚   â”œâ”€â”€ start_buddy.py          # Simple API server
â”‚   â”œâ”€â”€ emotion_engine.py       # Emotion analysis
â”‚   â””â”€â”€ lightweight_buddy.py    # Minimal version
â”‚
â”œâ”€â”€ ğŸ§ª Testing & Tools
â”‚   â”œâ”€â”€ test_syntax.py          # Syntax validator
â”‚   â”œâ”€â”€ run_tests.py            # Test suite
â”‚   â””â”€â”€ fix_torch.py            # PyTorch repair
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md               # This file
â”‚   â”œâ”€â”€ QUICKSTART.md           # Quick guide
â”‚   â”œâ”€â”€ FINAL_STATUS.md         # Status report
â”‚   â””â”€â”€ FIX_REPORT.md           # Technical docs
â”‚
â””â”€â”€ âš™ï¸ Configuration
    â”œâ”€â”€ requirements.txt        # Dependencies
    â”œâ”€â”€ config.json             # Model config
    â””â”€â”€ *.json                  # Tokenizer configs
```

### Key Files

| File | Purpose | Size |
|------|---------|------|
| `app.py` | Main entry point | 1.8KB |
| `core.py` | Core AI logic | 2.4KB |
| `speech.py` | Voice I/O | 1.2KB |
| `phi_inference.py` | Full API | 6.4KB |
| `emotion_engine.py` | Sentiment analysis | 3.6KB |

---

## âš™ï¸ Configuration

### Model Selection
Edit `config.py`:

```python
# Choose your language model
MODEL_NAME = "microsoft/phi-2"           # 2.7B params (default)
# MODEL_NAME = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"  # Lighter

# Sentiment & Emotion models
SENTIMENT_MODEL = "distilbert-base-uncased-finetuned-sst-2-english"
EMOTION_MODEL = "cardiffnlp/twitter-roberta-base-emotion"
```

### Response Parameters
Adjust in `core.py`:

```python
max_new_tokens = 64        # Response length
temperature = 0.6          # Creativity (0.1-1.0)
top_p = 0.9                # Nucleus sampling
repetition_penalty = 1.1   # Anti-repetition
```

### Safety Filter
Customize in `config.py`:

```python
SAFETY_FILTER = r"(?i)\b(sex|violence|hate|suicide|racism)\b"
```

---

## ğŸ”Œ API Reference

### REST Endpoints

#### POST /chat
Send message and get response

**Request**:
```json
{
  "text": "Your message",
  "use_cache": true
}
```

**Response** (200):
```json
{
  "response": "AI response",
  "status": "success"
}
```

**Error** (500):
```json
{
  "detail": "Error message"
}
```

### Python API

```python
from core import BuddyCore

# Initialize
buddy = BuddyCore()

# Generate response
response, time = buddy.generate_response("Hello!")
print(f"{response} ({time:.2f}s)")
```

---

## ğŸ§ª Testing

### Run All Tests
```bash
python run_tests.py
```

Tests:
- âœ… Syntax validation
- âœ… PyTorch import
- âœ… Transformers check
- âœ… Core module loading
- âœ… Speech verification
- âœ… Utils functionality

### Syntax Only
```bash
python test_syntax.py
```

### Manual Tests
```bash
# Test core
python -c "from core import BuddyCore; print('OK')"

# Test PyTorch
python -c "import torch; print(torch.__version__)"
```

---

## ğŸ”§ Troubleshooting

### 1. PyTorch DLL Error

**Error**: `OSError: [WinError 1114] DLL initialization failed`

**Fix**:
```bash
python fix_torch.py
```

Or manually:
```bash
pip uninstall -y torch torchvision torchaudio
pip install --user torch==2.5.0+cpu --index-url https://download.pytorch.org/whl/cpu
```

### 2. Module Not Found

**Error**: `ModuleNotFoundError`

**Fix**:
```bash
pip install --user -r requirements.txt
```

### 3. Voice Input Fails

**Issues**: Microphone not working

**Solutions**:
- Use text mode (option 2)
- Check microphone permissions
- Verify internet connection
- Install: `pip install --user pyaudio`

### 4. Slow First Run

**Issue**: Model download takes time

**Info**: First run downloads 8-10GB of models
- Wait 5-15 minutes
- Models cache to `~/.cache/huggingface/`
- Subsequent runs are fast

### 5. Memory Error

**Fix**:
- Close other applications
- Use lightweight mode
- Reduce `max_new_tokens`
- Switch to TinyLlama model

---

## âš¡ Performance

### Benchmarks (CPU Mode)

| Metric | Value |
|--------|-------|
| First Response | 5-30s |
| Subsequent | 2-5s |
| Memory Usage | 2-4 GB |
| Model Download | 5-15 min |
| Disk Space | 8-10 GB |

### System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| CPU | Dual-core | Quad-core+ |
| RAM | 4 GB | 8 GB |
| Storage | 10 GB | 20 GB |
| OS | Windows 10 | Windows 11 |

### Optimization

1. Use CPU-only PyTorch âœ… (configured)
2. Reduce `max_new_tokens` for speed
3. Enable Redis caching
4. Use TinyLlama for lighter model
5. Limit conversation history

---

## ğŸ“¦ Dependencies

### Core (Required)
```
torch>=2.0.0
transformers>=4.30.0
sentence-transformers>=2.2.2
speechrecognition>=3.10.0
pyttsx3>=2.90
numpy>=1.24.3
```

### Optional (Enhanced Features)
```
fastapi          # API server
uvicorn          # API runner
redis            # Caching
gtts             # Google TTS
pydub            # Audio
optimum          # ONNX optimization
onnxruntime      # ONNX runtime
keyboard         # Key handling
```

---

## ğŸ¯ Status & Roadmap

### âœ… Current Status (v1.0.0)
- All syntax errors fixed
- All core modules tested
- PyTorch CPU installed
- Comprehensive documentation
- Production ready

### ğŸš€ Future Plans
- [ ] GPU acceleration
- [ ] Multi-language support
- [ ] Web UI (React)
- [ ] Mobile app
- [ ] Docker support
- [ ] Custom fine-tuning
- [ ] Plugin system

---

## ğŸ“Š Project History

**October 30, 2025** - v1.0.0
- Fixed all syntax errors (7 total)
- Added comprehensive testing
- Created documentation suite
- Installed PyTorch CPU version
- Production ready release

### Fixed Issues
1. âœ… Indentation error (phi_inference.py)
2. âœ… Missing methods (speech.py, emotion_engine.py)
3. âœ… Decorator issues (buddy_api.py, phi_inference.py)
4. âœ… Import error handling
5. âœ… PyTorch DLL error
6. âœ… Unicode console encoding

---

## ğŸ™ Acknowledgments

- **Microsoft** - Phi-2 language model
- **HuggingFace** - Transformers & model hub
- **PyTorch** - Deep learning framework
- **FastAPI** - Web framework
- **Cardiff NLP** - Emotion models

---

## ğŸ“ Support

**Documentation**:
- `QUICKSTART.md` - Quick start guide
- `FINAL_STATUS.md` - Complete status report
- `FIX_REPORT.md` - Technical documentation

**Testing**:
```bash
python test_syntax.py   # Validate syntax
python run_tests.py     # Run all tests
python fix_torch.py     # Fix PyTorch
```

---

## ğŸ“ License

MIT License - Free for personal and commercial use

---

## ğŸ‘¨â€ğŸ’» Author

**Madhur Khara**

*An intelligent AI companion for everyday tasks*

---

## ğŸ‰ Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         BUDDY AI ASSISTANT              â”‚
â”‚         Quick Command Reference         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  START:        python app.py            â”‚
â”‚  TEST:         python test_syntax.py    â”‚
â”‚  FIX PYTORCH:  python fix_torch.py      â”‚
â”‚  API SERVER:   python start_buddy.py    â”‚
â”‚                                         â”‚
â”‚  Text Mode:    Select option 2          â”‚
â”‚  Voice Mode:   Select option 1          â”‚
â”‚  Exit:         Type "quit" or "exit"    â”‚
â”‚                                         â”‚
â”‚  First Run:    5-15 min (model download)â”‚
â”‚  Response:     2-5 seconds typical      â”‚
â”‚  Memory:       2-4 GB during use        â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Status**: âœ… Production Ready  
**Version**: 1.0.0  
**Last Updated**: October 30, 2025

**Ready to chat? Run:** `python app.py` ğŸš€
# buddy
